1
Thu Apr 13 20:05:49 2023       
+-----------------------------------------------------------------------------+
| NVIDIA-SMI 520.61.05    Driver Version: 520.61.05    CUDA Version: 11.8     |
|-------------------------------+----------------------+----------------------+
| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |
| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |
|                               |                      |               MIG M. |
|===============================+======================+======================|
|   0  NVIDIA A40          On   | 00000000:1D:00.0 Off |                    0 |
|  0%   28C    P8    30W / 300W |      0MiB / 46068MiB |      0%   E. Process |
|                               |                      |                  N/A |
+-------------------------------+----------------------+----------------------+
|   1  NVIDIA A40          On   | 00000000:1E:00.0 Off |                    0 |
|  0%   29C    P8    31W / 300W |      0MiB / 46068MiB |      0%   E. Process |
|                               |                      |                  N/A |
+-------------------------------+----------------------+----------------------+
|   2  NVIDIA A40          On   | 00000000:23:00.0 Off |                    0 |
|  0%   29C    P8    30W / 300W |      0MiB / 46068MiB |      0%   E. Process |
|                               |                      |                  N/A |
+-------------------------------+----------------------+----------------------+
|   3  NVIDIA A40          On   | 00000000:24:00.0 Off |                    0 |
|  0%   30C    P8    31W / 300W |      0MiB / 46068MiB |      0%   E. Process |
|                               |                      |                  N/A |
+-------------------------------+----------------------+----------------------+
                                                                               
+-----------------------------------------------------------------------------+
| Processes:                                                                  |
|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |
|        ID   ID                                                   Usage      |
|=============================================================================|
|  No running processes found                                                 |
+-----------------------------------------------------------------------------+
/home/advaiths/miniconda3/envs/clip/lib/python3.9/site-packages/pytorch_lightning/utilities/seed.py:48: LightningDeprecationWarning: `pytorch_lightning.utilities.seed.seed_everything` has been deprecated in v1.8.0 and will be removed in v1.10.0. Please use `lightning_lite.utilities.seed.seed_everything` instead.
  rank_zero_deprecation(
[rank: 0] Global seed set to 190223
Using 16bit native Automatic Mixed Precision (AMP)
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
Traceback (most recent call last):
  File "/home/advaiths/clip-slcd/MixVPR/main.py", line 397, in <module>
    trainer.fit(model=model, datamodule=datamodule)
  File "/home/advaiths/miniconda3/envs/clip/lib/python3.9/site-packages/pytorch_lightning/trainer/trainer.py", line 582, in fit
    call._call_and_handle_interrupt(
  File "/home/advaiths/miniconda3/envs/clip/lib/python3.9/site-packages/pytorch_lightning/trainer/call.py", line 38, in _call_and_handle_interrupt
    return trainer_fn(*args, **kwargs)
  File "/home/advaiths/miniconda3/envs/clip/lib/python3.9/site-packages/pytorch_lightning/trainer/trainer.py", line 624, in _fit_impl
    self._run(model, ckpt_path=self.ckpt_path)
  File "/home/advaiths/miniconda3/envs/clip/lib/python3.9/site-packages/pytorch_lightning/trainer/trainer.py", line 1042, in _run
    self.strategy.setup(self)
  File "/home/advaiths/miniconda3/envs/clip/lib/python3.9/site-packages/pytorch_lightning/strategies/single_device.py", line 74, in setup
    super().setup(trainer)
  File "/home/advaiths/miniconda3/envs/clip/lib/python3.9/site-packages/pytorch_lightning/strategies/strategy.py", line 154, in setup
    self.setup_optimizers(trainer)
  File "/home/advaiths/miniconda3/envs/clip/lib/python3.9/site-packages/pytorch_lightning/strategies/strategy.py", line 142, in setup_optimizers
    self.optimizers, self.lr_scheduler_configs, self.optimizer_frequencies = _init_optimizers_and_lr_schedulers(
  File "/home/advaiths/miniconda3/envs/clip/lib/python3.9/site-packages/pytorch_lightning/core/optimizer.py", line 195, in _init_optimizers_and_lr_schedulers
    _validate_scheduler_api(lr_scheduler_configs, model)
  File "/home/advaiths/miniconda3/envs/clip/lib/python3.9/site-packages/pytorch_lightning/core/optimizer.py", line 352, in _validate_scheduler_api
    raise MisconfigurationException(
lightning_lite.utilities.exceptions.MisconfigurationException: The provided lr scheduler `MultiStepLR` doesn't follow PyTorch's LRScheduler API. You should override the `LightningModule.lr_scheduler_step` hook with your own logic if you are using a custom LR scheduler.
